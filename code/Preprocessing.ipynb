{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this Script To get All Raw Data processed into preprocessed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- IQR to plot outliers\n",
    "- Use Median to avoid outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:32:18.813443Z",
     "start_time": "2021-08-14T14:32:16.886929Z"
    }
   },
   "outputs": [],
   "source": [
    "## Library\n",
    "\n",
    "# Spark:\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, datediff, round, lit, date_format, when, to_date\n",
    "import pyspark.sql.functions as F\n",
    "from os import path\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "from pyspark import SparkContext\n",
    "# create a spark session (which will run spark jobs)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "sc = SparkContext.getOrCreate(conf=swan_spark_conf) #Start the spark context\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:32:19.647083Z",
     "start_time": "2021-08-14T14:32:18.814755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Monitor\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate(conf=swan_spark_conf) #Start the spark context\n",
    "rdd = sc.parallelize([1, 2, 4, 8])\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:32:19.649276Z",
     "start_time": "2021-08-14T14:32:19.647870Z"
    }
   },
   "outputs": [],
   "source": [
    "holidays = [\n",
    "    \"2019-01-01\",\n",
    "    \"2019-01-21\",\n",
    "    \"2019-02-12\",\n",
    "    \"2019-02-18\",\n",
    "    \"2019-05-12\",\n",
    "    \"2019-05-27\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:32:19.654035Z",
     "start_time": "2021-08-14T14:32:19.649993Z"
    }
   },
   "outputs": [],
   "source": [
    "### Type Converter\n",
    "\n",
    "ints = ('VendorID', 'passenger_count', 'RateCodeID', 'RatecodeID','payment_type','PULocationID', 'DOLocationID')\n",
    "doubles = ('trip_distance', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "           'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount','congestion_surcharge')\n",
    "strings = ('hvfhs_license_num','dispatching_base_num','SR_Flag','store_and_fwd_flag', 'CarSpeed', 'EarnPerTime')\n",
    "dtimes = ('pickup_datetime', 'dropoff_datetime', )\n",
    "\n",
    "dtypes = {column: IntegerType() for column in ints}\n",
    "dtypes.update({column: DoubleType() for column in doubles})\n",
    "dtypes.update({column: StringType() for column in strings})\n",
    "dtypes.update({column: TimestampType() for column in dtimes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:32:19.658532Z",
     "start_time": "2021-08-14T14:32:19.655551Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def removeOutlier_IQR(spark_df, columns):\n",
    "    '''Use IQR to remove Outliers for each column in Spark Dataframe'''\n",
    "    for column in columns:\n",
    "        quantiles = spark_df.approxQuantile(column, [0.25,0.75], 0.01)\n",
    "        Q1 = quantiles[0]\n",
    "        Q3 = quantiles[1]\n",
    "        IQR = Q3 - Q1\n",
    "        lowerRange = Q1 - 1.5*IQR\n",
    "        upperRange = Q3 + 1.5*IQR\n",
    "        spark_df = spark_df.filter(col(column) > lowerRange).filter(col(column) < upperRange)\n",
    "    return spark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FHV Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:32:21.888749Z",
     "start_time": "2021-08-14T14:32:19.660171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- Shared: boolean (nullable = true)\n",
      " |-- Duration: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>dispatching_base_num</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>PULocationID</th><th>DOLocationID</th><th>Shared</th><th>Duration</th></tr>\n",
       "<tr><td>B00254</td><td>2019-01-01 00:33:03</td><td>2019-01-01 01:37:24</td><td>140</td><td>52</td><td>null</td><td>64</td></tr>\n",
       "<tr><td>B00254</td><td>2019-01-01 00:03:00</td><td>2019-01-01 00:34:25</td><td>141</td><td>237</td><td>null</td><td>31</td></tr>\n",
       "<tr><td>B00254</td><td>2019-01-01 00:45:48</td><td>2019-01-01 01:26:01</td><td>237</td><td>236</td><td>null</td><td>40</td></tr>\n",
       "<tr><td>B00254</td><td>2019-01-01 00:37:39</td><td>2019-01-01 01:44:59</td><td>162</td><td>85</td><td>null</td><td>67</td></tr>\n",
       "<tr><td>B00254</td><td>2019-01-01 00:35:06</td><td>2019-01-01 01:30:21</td><td>237</td><td>246</td><td>null</td><td>55</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+-------------------+-------------------+------------+------------+------+--------+\n",
       "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|Shared|Duration|\n",
       "+--------------------+-------------------+-------------------+------------+------------+------+--------+\n",
       "|              B00254|2019-01-01 00:33:03|2019-01-01 01:37:24|         140|          52|  null|      64|\n",
       "|              B00254|2019-01-01 00:03:00|2019-01-01 00:34:25|         141|         237|  null|      31|\n",
       "|              B00254|2019-01-01 00:45:48|2019-01-01 01:26:01|         237|         236|  null|      40|\n",
       "|              B00254|2019-01-01 00:37:39|2019-01-01 01:44:59|         162|          85|  null|      67|\n",
       "|              B00254|2019-01-01 00:35:06|2019-01-01 01:30:21|         237|         246|  null|      55|\n",
       "+--------------------+-------------------+-------------------+------------+------------+------+--------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## HVF Data\n",
    "\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "sdf_fhv = spark.read.csv('../raw_data/fhv_*', header=True)\n",
    "schema = StructType()\n",
    "for column in sdf_fhv.columns:\n",
    "    schema.add(column, # column name\n",
    "               dtypes[column], # data type\n",
    "               True # is nullable?\n",
    "              )\n",
    "\n",
    "# Load Data with predefined Schema\n",
    "sdf_fhv = spark.read.csv('../raw_data/fhv_*', header=True, schema=schema)\n",
    "\n",
    "\n",
    "# Drop Null\n",
    "sdf_fhv = sdf_fhv.filter(sdf_fhv.pickup_datetime>=lit('2019-01-01'))\n",
    "sdf_fhv = sdf_fhv.filter(sdf_fhv.pickup_datetime<=lit('2019-05-31'))\n",
    "sdf_fhv = sdf_fhv.filter(sdf_fhv.DOLocationID. isNotNull())\n",
    "sdf_fhv = sdf_fhv.filter(sdf_fhv.PULocationID. isNotNull())\n",
    "sdf_fhv = sdf_fhv.filter(sdf_fhv.dropoff_datetime. isNotNull())\n",
    "sdf_fhv = sdf_fhv.filter(sdf_fhv.pickup_datetime. isNotNull())\n",
    "\n",
    "sdf_fhv = sdf_fhv.withColumn(\"Shared\", (sdf_fhv[\"SR_Flag\"] != \"null\").cast(\"boolean\"))\n",
    "sdf_fhv = sdf_fhv.drop(\"SR_Flag\")\n",
    "\n",
    "\n",
    "## Add Duration Feature\n",
    "sdf_fhv = sdf_fhv.withColumn('Duration',col(\"dropoff_datetime\").cast(\"long\") - col('pickup_datetime').cast(\"long\"))\n",
    "sdf_fhv = sdf_fhv.withColumn('Duration',round(col('Duration')/60,3).cast(\"int\"))\n",
    "\n",
    "## Filtering\n",
    "sdf_fhv = sdf_fhv.filter(sdf_fhv.PULocationID > 0)\\\n",
    "        .filter(sdf_fhv.DOLocationID > 0)\\\n",
    "        .filter(sdf_fhv.Duration > 1)\\\n",
    "        .filter(sdf_fhv.Duration < 300)\n",
    "\n",
    "sdf_fhv.printSchema()\n",
    "sdf_fhv.dropna()\n",
    "sdf_fhv.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHV Daily Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:34:45.875092Z",
     "start_time": "2021-08-14T14:32:21.889680Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date</th><th>NumofPickUps</th><th>avg_duration</th><th>isWeekend</th><th>DayOfWeek</th></tr>\n",
       "<tr><td>2019-01-01</td><td>676778</td><td>16.77</td><td>true</td><td>Tue</td></tr>\n",
       "<tr><td>2019-01-02</td><td>484909</td><td>18.14</td><td>false</td><td>Wed</td></tr>\n",
       "<tr><td>2019-01-03</td><td>504065</td><td>18.23</td><td>false</td><td>Thu</td></tr>\n",
       "<tr><td>2019-01-04</td><td>581338</td><td>17.92</td><td>false</td><td>Fri</td></tr>\n",
       "<tr><td>2019-01-05</td><td>696771</td><td>16.81</td><td>true</td><td>Sat</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+------------+------------+---------+---------+\n",
       "|      date|NumofPickUps|avg_duration|isWeekend|DayOfWeek|\n",
       "+----------+------------+------------+---------+---------+\n",
       "|2019-01-01|      676778|       16.77|     true|      Tue|\n",
       "|2019-01-02|      484909|       18.14|    false|      Wed|\n",
       "|2019-01-03|      504065|       18.23|    false|      Thu|\n",
       "|2019-01-04|      581338|       17.92|    false|      Fri|\n",
       "|2019-01-05|      696771|       16.81|     true|      Sat|\n",
       "+----------+------------+------------+---------+---------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get Overall Data Frame For Each DAY\n",
    "\n",
    "sdf_fhv_new = sdf_fhv.withColumn(\"trips_count\", lit(1).cast(\"int\"))\n",
    "sdf_fhv_new = sdf_fhv_new.withColumn(\"date\",\n",
    "                      to_date(col(\"pickup_datetime\"),\"yyyy-MM-dd\"))\n",
    "\n",
    "sdf_fhv_data = sdf_fhv_new.groupby(sdf_fhv_new[\"date\"]).sum()\n",
    "sdf_fhv_data = sdf_fhv_data.withColumnRenamed(\"sum(trips_count)\", \"NumofPickUps\")\n",
    "sdf_fhv_data = sdf_fhv_data.withColumn(\"avg_duration\", round(sdf_fhv_data[\"sum(Duration)\"]/sdf_fhv_data[\"NumofPickUps\"],2))\n",
    "sdf_fhv_data = sdf_fhv_data.orderBy(\"date\")\n",
    "\n",
    "sdf_fhv_data = sdf_fhv_data.withColumn(\"isWeekend\", \n",
    "                                   when(((date_format(sdf_fhv_data[\"date\"], \"E\")) == \"Sat\") | \n",
    "                                    ((date_format(sdf_fhv_data[\"date\"], \"E\")) == \"Sun\")|\n",
    "                                        (date_format(sdf_fhv_data.date, 'yyyy-MM-dd').isin(holidays)), True).otherwise(False))\n",
    "sdf_fhv_data = sdf_fhv_data.withColumn(\"DayOfWeek\",date_format(sdf_fhv_data[\"date\"], \"E\"))\n",
    "\n",
    "sdf_fhv_data = sdf_fhv_data[\"date\", \"NumofPickUps\", \"avg_duration\", \"isWeekend\", \"DayOfWeek\"]\n",
    "sdf_fhv_data.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T10:47:04.648017Z",
     "start_time": "2021-08-03T10:47:04.646054Z"
    }
   },
   "source": [
    "## High Volumn FHV PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:34:46.239300Z",
     "start_time": "2021-08-14T14:34:45.875939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>hvfhs_license_num</th><th>dispatching_base_num</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>PULocationID</th><th>DOLocationID</th><th>Shared</th><th>Duration</th></tr>\n",
       "<tr><td>HV0003</td><td>B02867</td><td>2019-02-01 00:05:18</td><td>2019-02-01 00:14:57</td><td>245</td><td>251</td><td>null</td><td>9</td></tr>\n",
       "<tr><td>HV0003</td><td>B02879</td><td>2019-02-01 00:41:29</td><td>2019-02-01 00:49:39</td><td>216</td><td>197</td><td>null</td><td>8</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+--------------------+-------------------+-------------------+------------+------------+------+--------+\n",
       "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|Shared|Duration|\n",
       "+-----------------+--------------------+-------------------+-------------------+------------+------------+------+--------+\n",
       "|           HV0003|              B02867|2019-02-01 00:05:18|2019-02-01 00:14:57|         245|         251|  null|       9|\n",
       "|           HV0003|              B02879|2019-02-01 00:41:29|2019-02-01 00:49:39|         216|         197|  null|       8|\n",
       "+-----------------+--------------------+-------------------+-------------------+------------+------------+------+--------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## High Volumn FHV\n",
    "\n",
    "sdf_fhvhv = spark.read.csv('../raw_data/fhvhv*', header=True)\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "schema = StructType()\n",
    "for column in sdf_fhvhv.columns:\n",
    "    schema.add(column, # column name\n",
    "               dtypes[column], # data type\n",
    "               True # is nullable?\n",
    "              )\n",
    "\n",
    "# Load Data with predefined Schema\n",
    "sdf_fhvhv = spark.read.csv('../raw_data/fhvhv*', header=True, schema=schema)\n",
    "sdf_fhvhv\n",
    "sdf_fhvhv = sdf_fhvhv.withColumn(\"Shared\", (sdf_fhvhv[\"SR_Flag\"] == \"null\").cast(\"boolean\"))\n",
    "sdf_fhvhv = sdf_fhvhv.drop(\"SR_Flag\")\n",
    "\n",
    "# Drop Null\n",
    "sdf_fhvhv = sdf_fhvhv.filter(sdf_fhvhv.pickup_datetime>=lit('2019-02-01'))\n",
    "sdf_fhvhv = sdf_fhvhv.filter(sdf_fhvhv.pickup_datetime<=lit('2019-05-31'))\n",
    "sdf_fhvhv = sdf_fhvhv.filter(sdf_fhvhv.DOLocationID.isNotNull())\n",
    "sdf_fhvhv = sdf_fhvhv.filter(sdf_fhvhv.PULocationID.isNotNull())\n",
    "sdf_fhvhv = sdf_fhvhv.filter(sdf_fhvhv.dropoff_datetime.isNotNull())\n",
    "sdf_fhvhv = sdf_fhvhv.filter(sdf_fhvhv.pickup_datetime.isNotNull())\n",
    "\n",
    "\n",
    "## Add Duration Feature\n",
    "sdf_fhvhv = sdf_fhvhv.withColumn('Duration',col(\"dropoff_datetime\").cast(\"long\") - col('pickup_datetime').cast(\"long\"))\n",
    "sdf_fhvhv = sdf_fhvhv.withColumn('Duration',round(col('Duration')/60,3).cast(\"int\"))\n",
    "\n",
    "sdf_fhvhv.limit(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:34:46.457289Z",
     "start_time": "2021-08-14T14:34:46.240250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>hvfhs_license_num</th><th>dispatching_base_num</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>PULocationID</th><th>DOLocationID</th><th>Shared</th><th>Duration</th></tr>\n",
       "<tr><td>HV0003</td><td>B02867</td><td>2019-02-01 00:05:18</td><td>2019-02-01 00:14:57</td><td>245</td><td>251</td><td>null</td><td>9</td></tr>\n",
       "<tr><td>HV0003</td><td>B02879</td><td>2019-02-01 00:41:29</td><td>2019-02-01 00:49:39</td><td>216</td><td>197</td><td>null</td><td>8</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+--------------------+-------------------+-------------------+------------+------------+------+--------+\n",
       "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|Shared|Duration|\n",
       "+-----------------+--------------------+-------------------+-------------------+------------+------------+------+--------+\n",
       "|           HV0003|              B02867|2019-02-01 00:05:18|2019-02-01 00:14:57|         245|         251|  null|       9|\n",
       "|           HV0003|              B02879|2019-02-01 00:41:29|2019-02-01 00:49:39|         216|         197|  null|       8|\n",
       "+-----------------+--------------------+-------------------+-------------------+------------+------------+------+--------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Filtering\n",
    "\n",
    "sdf_fhvhv = sdf_fhvhv.filter(sdf_fhvhv.PULocationID > 0)\\\n",
    "        .filter(sdf_fhvhv.DOLocationID > 0)\\\n",
    "        .filter(sdf_fhvhv.Duration > 1)\\\n",
    "        .filter(sdf_fhvhv.Duration < 300)\n",
    "\n",
    "\n",
    "#print(f\"sdf_fhvhv Rows: {sdf_fhvhv.count()}\")\n",
    "sdf_fhvhv.limit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HV FHV Daily Data Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:41:07.807573Z",
     "start_time": "2021-08-14T14:34:46.458196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date</th><th>NumofPickUps</th><th>avg_duration</th><th>isWeekend</th><th>DayOfWeek</th></tr>\n",
       "<tr><td>2019-02-01</td><td>858400</td><td>18.68</td><td>false</td><td>Fri</td></tr>\n",
       "<tr><td>2019-02-02</td><td>864783</td><td>17.74</td><td>true</td><td>Sat</td></tr>\n",
       "<tr><td>2019-02-03</td><td>755193</td><td>17.05</td><td>true</td><td>Sun</td></tr>\n",
       "<tr><td>2019-02-04</td><td>591207</td><td>18.95</td><td>false</td><td>Mon</td></tr>\n",
       "<tr><td>2019-02-05</td><td>575586</td><td>18.57</td><td>false</td><td>Tue</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+------------+------------+---------+---------+\n",
       "|      date|NumofPickUps|avg_duration|isWeekend|DayOfWeek|\n",
       "+----------+------------+------------+---------+---------+\n",
       "|2019-02-01|      858400|       18.68|    false|      Fri|\n",
       "|2019-02-02|      864783|       17.74|     true|      Sat|\n",
       "|2019-02-03|      755193|       17.05|     true|      Sun|\n",
       "|2019-02-04|      591207|       18.95|    false|      Mon|\n",
       "|2019-02-05|      575586|       18.57|    false|      Tue|\n",
       "+----------+------------+------------+---------+---------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get Overall Data Frame For Each DAY\n",
    "\n",
    "sdf_fhvhv_new = sdf_fhvhv.withColumn(\"trips_count\", lit(1).cast(\"int\"))\n",
    "sdf_fhvhv_new = sdf_fhvhv_new.withColumn(\"date\",\n",
    "                      to_date(col(\"pickup_datetime\"),\"yyyy-MM-dd\"))\n",
    "\n",
    "sdf_fhvhv_data = sdf_fhvhv_new.groupby(sdf_fhvhv_new[\"date\"]).sum()\n",
    "sdf_fhvhv_data = sdf_fhvhv_data.withColumnRenamed(\"sum(trips_count)\", \"NumofPickUps\")\n",
    "sdf_fhvhv_data = sdf_fhvhv_data.withColumn(\"avg_duration\", round(sdf_fhvhv_data[\"sum(Duration)\"]/sdf_fhvhv_data[\"NumofPickUps\"],2))\n",
    "sdf_fhvhv_data = sdf_fhvhv_data.orderBy(\"date\")\n",
    "\n",
    "sdf_fhvhv_data = sdf_fhvhv_data.withColumn(\"isWeekend\", \n",
    "                                   when(((date_format(sdf_fhvhv_data[\"date\"], \"E\")) == \"Sat\") | \n",
    "                                    ((date_format(sdf_fhvhv_data[\"date\"], \"E\")) == \"Sun\")|\n",
    "                                        (date_format(sdf_fhvhv_data.date, 'yyyy-MM-dd').isin(holidays)), True).otherwise(False))\n",
    "sdf_fhvhv_data = sdf_fhvhv_data.withColumn(\"DayOfWeek\",date_format(sdf_fhvhv_data[\"date\"], \"E\"))\n",
    "\n",
    "sdf_fhvhv_data = sdf_fhvhv_data[\"date\", \"NumofPickUps\", \"avg_duration\", \"isWeekend\", \"DayOfWeek\"]\n",
    "sdf_fhvhv_data.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yellow Taxi PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:41:08.038143Z",
     "start_time": "2021-08-14T14:41:07.808470Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>store_and_fwd</th></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:46:40</td><td>2019-01-01 00:53:20</td><td>1</td><td>1.5</td><td>1</td><td>151</td><td>239</td><td>1</td><td>7.0</td><td>0.5</td><td>0.5</td><td>1.65</td><td>0.0</td><td>0.3</td><td>9.95</td><td>null</td><td>false</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:59:47</td><td>2019-01-01 01:18:59</td><td>1</td><td>2.6</td><td>1</td><td>239</td><td>246</td><td>1</td><td>14.0</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>16.3</td><td>null</td><td>false</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------+\n",
       "|VendorID|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|RatecodeID|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|store_and_fwd|\n",
       "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------+\n",
       "|       1|2019-01-01 00:46:40|2019-01-01 00:53:20|              1|          1.5|         1|         151|         239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                null|        false|\n",
       "|       1|2019-01-01 00:59:47|2019-01-01 01:18:59|              1|          2.6|         1|         239|         246|           1|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                null|        false|\n",
       "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Yellow Taxi\n",
    "\n",
    "#sdf_yellow.describe(\"congestion_surcharge\").show()\n",
    "\n",
    "sdf_yellow = spark.read.csv('../raw_data/yellow*', header=True)\\\n",
    "                .withColumnRenamed(\"tpep_pickup_datetime\",\"pickup_datetime\")\\\n",
    "                .withColumnRenamed(\"tpep_dropoff_datetime\",\"dropoff_datetime\") # rename the wrong column\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "schema = StructType()\n",
    "for column in sdf_yellow.columns:\n",
    "    schema.add(column, # column name\n",
    "               dtypes[column], # data type\n",
    "               True # is nullable?\n",
    "              )\n",
    "    \n",
    "sdf_yellow = spark.read.csv('../raw_data/yellow*', header=True, schema=schema)\n",
    "\n",
    "sdf_yellow = sdf_yellow.withColumn(\"store_and_fwd\", (sdf_yellow[\"store_and_fwd_flag\"] == \"Y\").cast(\"boolean\"))\n",
    "sdf_yellow = sdf_yellow.drop(\"store_and_fwd_flag\")\n",
    "#sdf_yellow.printSchema()\n",
    "#print(f\"row Count before Preprocessing: {sdf_yellow.count()}\")\n",
    "sdf_yellow.limit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "- Add Duration in minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:41:08.269417Z",
     "start_time": "2021-08-14T14:41:08.039102Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>store_and_fwd</th><th>Duration</th><th>CarSpeed</th><th>EarnPerTime</th><th>isWeekend</th></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:46:40</td><td>2019-01-01 00:53:20</td><td>1</td><td>1.5</td><td>1</td><td>151</td><td>239</td><td>1</td><td>7.0</td><td>0.5</td><td>0.5</td><td>1.65</td><td>0.0</td><td>0.3</td><td>9.95</td><td>null</td><td>false</td><td>6</td><td>15.0</td><td>1.658</td><td>true</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:59:47</td><td>2019-01-01 01:18:59</td><td>1</td><td>2.6</td><td>1</td><td>239</td><td>246</td><td>1</td><td>14.0</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>16.3</td><td>null</td><td>false</td><td>19</td><td>8.211</td><td>0.858</td><td>true</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------+--------+--------+-----------+---------+\n",
       "|VendorID|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|RatecodeID|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|store_and_fwd|Duration|CarSpeed|EarnPerTime|isWeekend|\n",
       "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------+--------+--------+-----------+---------+\n",
       "|       1|2019-01-01 00:46:40|2019-01-01 00:53:20|              1|          1.5|         1|         151|         239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                null|        false|       6|    15.0|      1.658|     true|\n",
       "|       1|2019-01-01 00:59:47|2019-01-01 01:18:59|              1|          2.6|         1|         239|         246|           1|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                null|        false|      19|   8.211|      0.858|     true|\n",
       "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------+--------+--------+-----------+---------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add Duration Label in rounded minutes\n",
    "sdf_yellow = sdf_yellow.withColumn('Duration',col(\"dropoff_datetime\").cast(\"long\") - col('pickup_datetime').cast(\"long\"))\n",
    "\n",
    "# Car Speed is Miles/Hour\n",
    "sdf_yellow = sdf_yellow.withColumn('Duration',round(col('Duration')/60,3).cast(\"int\"))\n",
    "sdf_yellow = sdf_yellow.withColumn('CarSpeed',round(col('trip_distance')/col('Duration')*60,3).cast(\"double\"))\n",
    "sdf_yellow = sdf_yellow.withColumn('EarnPerTime',round(col('total_amount')/col('Duration'),3).cast(\"double\"))\n",
    "sdf_yellow = sdf_yellow.withColumn(\"isWeekend\", \n",
    "                                   when(((date_format(sdf_yellow[\"pickup_datetime\"], \"E\")) == \"Sat\") | \n",
    "                                    ((date_format(sdf_yellow[\"pickup_datetime\"], \"E\")) == \"Sun\") |\n",
    "                                        (date_format(sdf_yellow[\"pickup_datetime\"], 'yyyy-MM-dd').isin(holidays)), True).otherwise(False))\n",
    "sdf_yellow.limit(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanse\n",
    "Use Basic Knowledge to do data Scleansing\n",
    "\n",
    "Some Data is Faulty:\n",
    "\n",
    "- fare = 0\n",
    "- pick up dropoff time reversed, distance too large\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:46:30.369295Z",
     "start_time": "2021-08-14T14:41:08.270339Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>store_and_fwd</th><th>Duration</th><th>CarSpeed</th><th>EarnPerTime</th><th>isWeekend</th></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:46:40</td><td>2019-01-01 00:53:20</td><td>1</td><td>1.5</td><td>1</td><td>151</td><td>239</td><td>1</td><td>7.0</td><td>0.5</td><td>0.5</td><td>1.65</td><td>0.0</td><td>0.3</td><td>9.95</td><td>null</td><td>false</td><td>6</td><td>15.0</td><td>1.658</td><td>true</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:59:47</td><td>2019-01-01 01:18:59</td><td>1</td><td>2.6</td><td>1</td><td>239</td><td>246</td><td>1</td><td>14.0</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>16.3</td><td>null</td><td>false</td><td>19</td><td>8.211</td><td>0.858</td><td>true</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:21:28</td><td>2019-01-01 00:28:37</td><td>1</td><td>1.3</td><td>1</td><td>163</td><td>229</td><td>1</td><td>6.5</td><td>0.5</td><td>0.5</td><td>1.25</td><td>0.0</td><td>0.3</td><td>9.05</td><td>null</td><td>false</td><td>7</td><td>11.143</td><td>1.293</td><td>true</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:32:01</td><td>2019-01-01 00:45:39</td><td>1</td><td>3.7</td><td>1</td><td>229</td><td>7</td><td>1</td><td>13.5</td><td>0.5</td><td>0.5</td><td>3.7</td><td>0.0</td><td>0.3</td><td>18.5</td><td>null</td><td>false</td><td>13</td><td>17.077</td><td>1.423</td><td>true</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:57:32</td><td>2019-01-01 01:09:32</td><td>2</td><td>2.1</td><td>1</td><td>141</td><td>234</td><td>1</td><td>10.0</td><td>0.5</td><td>0.5</td><td>1.7</td><td>0.0</td><td>0.3</td><td>13.0</td><td>null</td><td>false</td><td>12</td><td>10.5</td><td>1.083</td><td>true</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------+--------+--------+-----------+---------+\n",
       "|VendorID|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|RatecodeID|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|store_and_fwd|Duration|CarSpeed|EarnPerTime|isWeekend|\n",
       "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------+--------+--------+-----------+---------+\n",
       "|       1|2019-01-01 00:46:40|2019-01-01 00:53:20|              1|          1.5|         1|         151|         239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                null|        false|       6|    15.0|      1.658|     true|\n",
       "|       1|2019-01-01 00:59:47|2019-01-01 01:18:59|              1|          2.6|         1|         239|         246|           1|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                null|        false|      19|   8.211|      0.858|     true|\n",
       "|       1|2019-01-01 00:21:28|2019-01-01 00:28:37|              1|          1.3|         1|         163|         229|           1|        6.5|  0.5|    0.5|      1.25|         0.0|                  0.3|        9.05|                null|        false|       7|  11.143|      1.293|     true|\n",
       "|       1|2019-01-01 00:32:01|2019-01-01 00:45:39|              1|          3.7|         1|         229|           7|           1|       13.5|  0.5|    0.5|       3.7|         0.0|                  0.3|        18.5|                null|        false|      13|  17.077|      1.423|     true|\n",
       "|       1|2019-01-01 00:57:32|2019-01-01 01:09:32|              2|          2.1|         1|         141|         234|           1|       10.0|  0.5|    0.5|       1.7|         0.0|                  0.3|        13.0|                null|        false|      12|    10.5|      1.083|     true|\n",
       "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------+--------+--------+-----------+---------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep 2019 data\n",
    "# Remove Trip distance < 0.5 Miles\n",
    "# Remove Trip distance > 150 Miles\n",
    "# Remove Passenger count = 0\n",
    "# Remove fare amount = 0\n",
    "# Remove Duration < 1 mins\n",
    "# Remove Duration > 10 hours\n",
    "# Remove Where Extra charge < 0 \n",
    "# Remove Total Amount < $1\n",
    "# Filter Null Value for pick up location\n",
    "# Filter Null Value for Dropoff location\n",
    "sdf_yellow = sdf_yellow\\\n",
    "    .filter(sdf_yellow.pickup_datetime >= lit(\"2019-01-01\"))\\\n",
    "    .filter(sdf_yellow.pickup_datetime <= lit(\"2019-05-31\"))\\\n",
    "    .filter(sdf_yellow.trip_distance > 0.5)\\\n",
    "    .filter(sdf_yellow.passenger_count > 0)\\\n",
    "    .filter(sdf_yellow.fare_amount > 0)\\\n",
    "    .filter(sdf_yellow.Duration > 1)\\\n",
    "    .filter(sdf_yellow.extra >= 0 )\\\n",
    "    .filter(sdf_yellow.PULocationID.isNotNull())\\\n",
    "    .filter(sdf_yellow.DOLocationID.isNotNull())\\\n",
    "    .filter((sdf_yellow.payment_type == 1) | (sdf_yellow.payment_type == 2))\n",
    "\n",
    "# filter(sdf_yellow.trip_distance < 150)\n",
    "# filter(sdf_yellow.Duration < 600)\n",
    "\n",
    "#print(f\"Rows before Preprocessing: {sdf_yellow.count()}\")\n",
    "\n",
    "# Use IQR for fare_amount, DurationEarn/Miles and Car Speed As well\n",
    "sdf_yellow = removeOutlier_IQR(sdf_yellow, [\"trip_distance\"])\n",
    "sdf_yellow = removeOutlier_IQR(sdf_yellow, [\"total_amount\", \"Duration\"])\n",
    "sdf_yellow.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer For Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:46:30.453746Z",
     "start_time": "2021-08-14T14:46:30.370115Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get Overall Data Frame For Each DAY\n",
    "\n",
    "sdf_yellow_new = sdf_yellow.withColumn(\"trips_count\", lit(1).cast(\"int\"))\n",
    "sdf_yellow_new = sdf_yellow_new.withColumn(\"date\",\n",
    "                      to_date(col(\"pickup_datetime\"),\"yyyy-MM-dd\"))\n",
    "\n",
    "sum_yellow_data = sdf_yellow_new.groupby(sdf_yellow_new[\"date\"]).sum()\n",
    "sum_yellow_data = sum_yellow_data.withColumnRenamed(\"sum(trips_count)\", \"NumofPickUps\")\n",
    "sum_yellow_data = sum_yellow_data.withColumn(\"avg_speed\", round(sum_yellow_data[\"sum(CarSpeed)\"]/sum_yellow_data[\"NumofPickUps\"],5))\n",
    "sum_yellow_data = sum_yellow_data.withColumn(\"avg_earn\", round(sum_yellow_data[\"sum(total_amount)\"]/sum_yellow_data[\"NumofPickUps\"],3))\n",
    "sum_yellow_data = sum_yellow_data.withColumn(\"avg_duration\", round(sum_yellow_data[\"sum(Duration)\"]/sum_yellow_data[\"NumofPickUps\"],3))\n",
    "sum_yellow_data = sum_yellow_data.withColumn(\"avg_fare_amount\", round(sum_yellow_data[\"sum(fare_amount)\"]/sum_yellow_data[\"NumofPickUps\"],3))\n",
    "sum_yellow_data = sum_yellow_data.withColumn(\"avg_trip_distance\", round(sum_yellow_data[\"sum(trip_distance)\"]/sum_yellow_data[\"NumofPickUps\"],5))\n",
    "sum_yellow_data = sum_yellow_data.orderBy(\"date\")\n",
    "\n",
    "sum_yellow_data = sum_yellow_data.withColumn(\"isWeekend\", \n",
    "                                   when(((date_format(sum_yellow_data[\"date\"], \"E\")) == \"Sat\") | \n",
    "                                    ((date_format(sum_yellow_data[\"date\"], \"E\")) == \"Sun\") | \n",
    "                                        (date_format(sum_yellow_data[\"date\"], 'yyyy-MM-dd').isin(holidays)), True).otherwise(False))\n",
    "\n",
    "sum_yellow_data = sum_yellow_data.withColumn(\"DayOfWeek\",date_format(sum_yellow_data[\"date\"], \"E\"))\n",
    "\n",
    "sum_yellow_data = sum_yellow_data[\"date\", \"NumofPickUps\", \"avg_duration\", \"avg_trip_distance\", \"avg_earn\", \"avg_speed\", \"avg_fare_amount\", \"isWeekend\", \"DayOfWeek\"]\n",
    "#sum_yellow_data.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T10:10:17.851714Z",
     "start_time": "2021-08-03T10:10:12.349Z"
    }
   },
   "source": [
    "## Green Taxi PreProcessing\n",
    "\n",
    "- Drop column ehail_fee as all the values are null\n",
    "- \"trip_type\" Drop this column as this attribute not appeared in green taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:46:30.697773Z",
     "start_time": "2021-08-14T14:46:30.454761Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before Preprocessing: 2196066\n"
     ]
    }
   ],
   "source": [
    "## Green Taxi\n",
    "\n",
    "#sdf_green.describe(\"congestion_surcharge\").show()\n",
    "\n",
    "sdf_green = spark.read.csv('../raw_data/green*', header=True)\\\n",
    "                .withColumnRenamed(\"lpep_pickup_datetime\",\"pickup_datetime\")\\\n",
    "                .withColumnRenamed(\"lpep_dropoff_datetime\",\"dropoff_datetime\") # rename the wrong column\n",
    "sdf_green = sdf_green.drop(\"ehail_fee\")  # Drop this column as all the values are null\n",
    "sdf_green = sdf_green.drop(\"trip_type\")  # Drop this column as this attribute not appeared in green taxi\n",
    "sdf_green = sdf_green.drop(\"improvement_surcharge\")\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "schema = StructType()\n",
    "for column in sdf_green.columns:\n",
    "    schema.add(column, # column name\n",
    "               dtypes[column], # data type\n",
    "               True # is nullable?\n",
    "              )\n",
    "    \n",
    "sdf_green = spark.read.csv('../raw_data/green*', header=True, schema=schema)\n",
    "\n",
    "sdf_green = sdf_green.withColumn(\"store_and_fwd\", (sdf_green[\"store_and_fwd_flag\"] == \"Y\").cast(\"boolean\"))\n",
    "sdf_green = sdf_green.drop(\"store_and_fwd_flag\")\n",
    "#sdf_green.printSchema()\n",
    "print(f\"Rows before Preprocessing: {sdf_green.count()}\")\n",
    "#sdf_green.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering add duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:46:30.862924Z",
     "start_time": "2021-08-14T14:46:30.698833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>RatecodeID</th><th>PULocationID</th><th>DOLocationID</th><th>passenger_count</th><th>trip_distance</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>total_amount</th><th>payment_type</th><th>congestion_surcharge</th><th>store_and_fwd</th><th>Duration</th><th>CarSpeed</th><th>EarnPerTime</th></tr>\n",
       "<tr><td>2</td><td>2019-02-01 00:10:19</td><td>2019-02-01 00:21:43</td><td>1</td><td>92</td><td>135</td><td>1</td><td>2.79</td><td>11.0</td><td>0.5</td><td>0.5</td><td>3.08</td><td>0.0</td><td>null</td><td>null</td><td>15.38</td><td>false</td><td>11</td><td>15.218</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-02-01 00:02:16</td><td>2019-02-01 00:24:37</td><td>1</td><td>66</td><td>36</td><td>1</td><td>4.46</td><td>17.5</td><td>0.5</td><td>0.5</td><td>3.76</td><td>0.0</td><td>null</td><td>null</td><td>22.56</td><td>false</td><td>22</td><td>12.164</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-------------------+-------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+------------+------------+--------------------+-------------+--------+--------+-----------+\n",
       "|VendorID|    pickup_datetime|   dropoff_datetime|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|total_amount|payment_type|congestion_surcharge|store_and_fwd|Duration|CarSpeed|EarnPerTime|\n",
       "+--------+-------------------+-------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+------------+------------+--------------------+-------------+--------+--------+-----------+\n",
       "|       2|2019-02-01 00:10:19|2019-02-01 00:21:43|         1|          92|         135|              1|         2.79|       11.0|  0.5|    0.5|      3.08|         0.0|        null|        null|               15.38|        false|      11|  15.218|       null|\n",
       "|       2|2019-02-01 00:02:16|2019-02-01 00:24:37|         1|          66|          36|              1|         4.46|       17.5|  0.5|    0.5|      3.76|         0.0|        null|        null|               22.56|        false|      22|  12.164|       null|\n",
       "+--------+-------------------+-------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+------------+------------+--------------------+-------------+--------+--------+-----------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add Duration Label in rounded minutes\n",
    "sdf_green = sdf_green.withColumn('Duration',col(\"dropoff_datetime\").cast(\"long\") - col('pickup_datetime').cast(\"long\"))\n",
    "\n",
    "sdf_green = sdf_green.withColumn('Duration',round(col('Duration')/60,3).cast(\"int\"))\n",
    "sdf_green = sdf_green.withColumn('CarSpeed',round(col('trip_distance')/col('Duration')*60,3).cast(\"double\"))\n",
    "sdf_green = sdf_green.withColumn('EarnPerTime',round(col('total_amount')/col('Duration'),3).cast(\"double\"))\n",
    "sdf_green.limit(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T10:29:13.908582Z",
     "start_time": "2021-08-03T10:29:09.824769Z"
    }
   },
   "source": [
    "## Cleanse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:46:36.835285Z",
     "start_time": "2021-08-14T14:46:30.863847Z"
    }
   },
   "outputs": [],
   "source": [
    "# .filter(sdf_green.pickup_datetime >= lit(\"2019-01-01\"))\\\n",
    "# Remove Trip distance < 0.1 Miles\n",
    "# Remove Trip distance > 150 Miles\n",
    "# Remove Passenger count = 0\n",
    "# Remove fare amount = 0\n",
    "# Remove Duration < 1 mins\n",
    "# Remove Duration > 10 hours\n",
    "# Remove Where Extra charge < 0 \n",
    "# Remove Total Amount < $1\n",
    "# Filter Null Value for pick up location\n",
    "# Filter Null Value for Dropoff location\n",
    "sdf_green = sdf_green\\\n",
    "    .filter(sdf_green.pickup_datetime >= lit(\"2019-01-01\"))\\\n",
    "    .filter(sdf_green.pickup_datetime <= lit(\"2019-05-31\"))\\\n",
    "    .filter(sdf_green.trip_distance > 0.5)\\\n",
    "    .filter(sdf_green.passenger_count > 0)\\\n",
    "    .filter(sdf_green.fare_amount > 0)\\\n",
    "    .filter(sdf_green.Duration > 1)\\\n",
    "    .filter(sdf_green.Duration < 600)\\\n",
    "    .filter(sdf_green.extra >= 0 )\\\n",
    "    .filter(sdf_green.PULocationID.isNotNull() )\\\n",
    "    .filter(sdf_green.DOLocationID.isNotNull())\n",
    "\n",
    "sdf_green = removeOutlier_IQR(sdf_green, [\"trip_distance\"])\n",
    "\n",
    "#print(f\"Rows after Preprocessing: {sdf_green.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Green Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T14:46:36.910988Z",
     "start_time": "2021-08-14T14:46:36.836259Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get Overall Data Frame For Each DAY\n",
    "\n",
    "sdf_green_new = sdf_green.withColumn(\"trips_count\", lit(1).cast(\"int\"))\n",
    "sdf_green_new = sdf_green_new.withColumn(\"date\",\n",
    "                      to_date(col(\"pickup_datetime\"),\"yyyy-MM-dd\"))\n",
    "\n",
    "sum_green_data = sdf_green_new.groupby(sdf_green_new[\"date\"]).sum()\n",
    "sum_green_data = sum_green_data.withColumnRenamed(\"sum(trips_count)\", \"NumofPickUps\")\n",
    "sum_green_data = sum_green_data.withColumn(\"avg_speed\", round(sum_green_data[\"sum(CarSpeed)\"]/sum_green_data[\"NumofPickUps\"],5))\n",
    "sum_green_data = sum_green_data.withColumn(\"avg_earn\", round(sum_green_data[\"sum(total_amount)\"]/sum_green_data[\"NumofPickUps\"],3))\n",
    "sum_green_data = sum_green_data.withColumn(\"avg_duration\", round(sum_green_data[\"sum(Duration)\"]/sum_green_data[\"NumofPickUps\"],3))\n",
    "sum_green_data = sum_green_data.withColumn(\"avg_fare_amount\", round(sum_green_data[\"sum(fare_amount)\"]/sum_green_data[\"NumofPickUps\"],3))\n",
    "sum_green_data = sum_green_data.withColumn(\"avg_trip_distance\", round(sum_green_data[\"sum(trip_distance)\"]/sum_green_data[\"NumofPickUps\"],5))\n",
    "sum_green_data = sum_green_data.orderBy(\"date\")\n",
    "\n",
    "sum_green_data = sum_green_data.withColumn(\"isWeekend\", \n",
    "                                   when(((date_format(sum_green_data[\"date\"], \"E\")) == \"Sat\") | \n",
    "                                    ((date_format(sum_green_data[\"date\"], \"E\")) == \"Sun\") | \n",
    "                                        (date_format(sum_green_data[\"date\"], 'yyyy-MM-dd').isin(holidays)), True).otherwise(False))\n",
    "\n",
    "sum_green_data = sum_green_data.withColumn(\"DayOfWeek\",date_format(sum_green_data[\"date\"], \"E\"))\n",
    "\n",
    "sum_green_data = sum_green_data[\"date\", \"NumofPickUps\", \"avg_duration\", \"avg_trip_distance\", \"avg_earn\", \"avg_speed\", \"avg_fare_amount\", \"isWeekend\", \"DayOfWeek\"]\n",
    "#sum_green_data.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data To Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T15:00:18.576010Z",
     "start_time": "2021-08-14T14:46:36.911994Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check to see if the fpath already exists. If so, remove it.\n",
    "from shutil import rmtree\n",
    "from os import path\n",
    "\n",
    "fpath = '../preprocessed_data/yellow.parquet/'\n",
    "if path.exists(fpath):\n",
    "    rmtree(fpath)\n",
    "sdf_yellow.write.format('parquet').save(fpath)\n",
    "\n",
    "fpath = '../preprocessed_data/yellow_daily.parquet/'\n",
    "if path.exists(fpath):\n",
    "    rmtree(fpath)\n",
    "sum_yellow_data.write.format('parquet').save(fpath)\n",
    "    \n",
    "    \n",
    "fpath = '../preprocessed_data/green.parquet/'\n",
    "if path.exists(fpath):\n",
    "    rmtree(fpath)\n",
    "sdf_green.write.format('parquet').save(fpath)\n",
    "\n",
    "fpath = '../preprocessed_data/green_daily.parquet/'\n",
    "if path.exists(fpath):\n",
    "    rmtree(fpath)\n",
    "sum_green_data.write.format('parquet').save(fpath)\n",
    "    \n",
    "fpath = '../preprocessed_data/fhv.parquet/'\n",
    "if path.exists(fpath):\n",
    "    rmtree(fpath)\n",
    "sdf_fhv.write.format('parquet').save(fpath)\n",
    "\n",
    "fpath = '../preprocessed_data/fhv_daily.parquet/'\n",
    "if path.exists(fpath):\n",
    "    rmtree(fpath)\n",
    "sdf_fhv_data.write.format('parquet').save(fpath)\n",
    "\n",
    "fpath = '../preprocessed_data/hvfhv.parquet/'\n",
    "if path.exists(fpath):\n",
    "    rmtree(fpath)\n",
    "sdf_fhvhv.write.format('parquet').save(fpath)\n",
    "\n",
    "fpath = '../preprocessed_data/hvfhv_daily.parquet/'\n",
    "if path.exists(fpath):\n",
    "    rmtree(fpath)\n",
    "sdf_fhvhv_data.write.format('parquet').save(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T15:02:02.733989Z",
     "start_time": "2021-08-14T15:00:18.577342Z"
    }
   },
   "outputs": [],
   "source": [
    "fpath = '../preprocessed_data/green_daily.parquet/'\n",
    "if path.exists(fpath):\n",
    "    rmtree(fpath)\n",
    "sum_green_data.write.format('parquet').save(fpath)\n",
    "fpath = '../preprocessed_data/yellow_daily.parquet/'\n",
    "if path.exists(fpath):\n",
    "    rmtree(fpath)\n",
    "sum_yellow_data.write.format('parquet').save(fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
